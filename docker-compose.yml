services:
  zookeeper:
    image: confluentinc/cp-zookeeper:7.6.1
    hostname: zookeeper
    container_name: zookeeper
    ports:
      - 22181:2181
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_SERVER_ID: 1
      ZOOKEEPER_SERVERS: zookeeper:2888:3888
    volumes:
      - zookeeper_data:/var/lib/zookeeper
    networks:
      - red-proyecto
    restart: always

  kafka1:
    image: confluentinc/cp-kafka:7.6.1
    hostname: kafka1
    container_name: kafka1
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka1:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 3
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 2
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
    volumes:
      - kafka1_data:/var/lib/kafka
    depends_on:
      - zookeeper
    networks:
      - red-proyecto
    restart: always

  kafka2:
    image: confluentinc/cp-kafka:7.6.1
    hostname: kafka2
    container_name: kafka2
    ports:
      - "9093:9092"
    environment:
      KAFKA_BROKER_ID: 2
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka2:9093
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 3
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 2
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
    volumes:
      - kafka2_data:/var/lib/kafka
    depends_on:
      - zookeeper
    networks:
      - red-proyecto
    restart: always

  kafka3:
    image: confluentinc/cp-kafka:7.6.1
    hostname: kafka3
    container_name: kafka3
    ports:
      - "9094:9092"
    environment:
      KAFKA_BROKER_ID: 3
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka3:9094
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 3
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 2
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
    volumes:
      - kafka3_data:/var/lib/kafka
    depends_on:
      - zookeeper
    networks:
      - red-proyecto
    restart: always

  schema-registry:
    image: confluentinc/cp-schema-registry:7.6.1
    hostname: schema-registry
    container_name: schema-registry
    ports:
      - "8081:8081"
    environment:
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: PLAINTEXT://kafka1:9092,PLAINTEXT://kafka2:9093,PLAINTEXT://kafka3:9094
      SCHEMA_REGISTRY_HOST_NAME: schema-registry
      SCHEMA_REGISTRY_LISTENERS: http://0.0.0.0:8081
    volumes:
      - schema_registry_data:/var/lib/schema-registry
    depends_on:
      - zookeeper
      - kafka1
      - kafka2
      - kafka3
    networks:
      - red-proyecto
    restart: always

  spark-master:
    image: bitnami/spark:3.5.1
    hostname: spark-master
    container_name: spark-master
    user: root
    environment:
      - SPARK_MODE=master
    volumes:
      - spark_master_data:/opt/bitnami/spark
    ports:
      - "8080:8080"
      - "7077:7077"
    networks:
      - red-proyecto
    restart: always

  spark-worker:
    image: bitnami/spark:3.5.1
    user: root
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
    volumes:
      - spark_worker_data:/opt/bitnami/spark
    depends_on:
      - spark-master
    networks:
      - red-proyecto
    restart: always

  spark-submit:
    build:
      context: .
      dockerfile: ./spark/Dockerfile
    user: root
    hostname: spark-submit
    container_name: spark-submit
    depends_on:
      - spark-master
      - spark-worker
    volumes:
      - spark_submit_data:/opt/bitnami/spark
      - nltk_data:/opt/bitnami/nltk_data
    networks:
      - red-proyecto
    restart: always

  leer_tweets:
    build:
      context: .
      dockerfile: ./leer_tweets/Dockerfile
    hostname: leer_tweets
    container_name: leer_tweets
    volumes:
      - ./leer_tweets/:/app
      - ./data/:/data
    working_dir: /app
    command: python -u producer.py
    depends_on:
      - kafka1
      - kafka2
      - kafka3
      - zookeeper
    networks:
      - red-proyecto
    restart: always

  jupyter:
    image: jupyter/pyspark-notebook
    hostname: jupyter
    container_name: jupyter
    environment:
      - JUPYTER_ENABLE_LAB=yes
      - PYSPARK_SUBMIT_ARGS=--master spark://spark-master:7077 pyspark-shell
    ports:
      - '8888:8888'
    volumes:
      - ./spark/notebooks:/home/jovyan/work
    depends_on:
      - spark-master
      - spark-worker
      - spark-submit
    networks:
      - red-proyecto
    restart: always

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.9.3
    hostname: elasticsearch
    container_name: elasticsearch
    environment:
      - discovery.type=single-node
      - node.name=elasticsearch
      - cluster.name=elasticsearch
      - bootstrap.memory_lock=true
      - ES_JAVA_OPTS=-Xms512m -Xmx512m
    ulimits:
      memlock:
        soft: -1
        hard: -1
    ports:
      - "9200:9200"
      - "9300:9300"
    volumes:
      - es_data:/usr/share/elasticsearch/data
    networks:
      - red-proyecto
    restart: always

  kibana:
    image: docker.elastic.co/kibana/kibana:7.9.3
    hostname: kibana
    container_name: kibana
    ports:
      - "5601:5601"
    environment:
      ELASTICSEARCH_URL: "http://elasticsearch:9200"
      ELASTICSEARCH_HOSTS: '["http://elasticsearch:9200"]'
    depends_on:
      - elasticsearch
    networks:
      - red-proyecto
    restart: always

networks:
  red-proyecto:
    driver: bridge

volumes:
  zookeeper_data:
  kafka1_data:
  kafka2_data:
  kafka3_data:
  schema_registry_data:
  spark_master_data:
  spark_worker_data:
  spark_submit_data:
  nltk_data:
  es_data: